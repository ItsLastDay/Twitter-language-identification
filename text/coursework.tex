\documentclass[a4paper, 14pt]{article}
\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[dvips]{graphicx, color}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{fancyref}
\usepackage{indentfirst}
\usepackage{extsizes}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{multirow} % улучшенное форматирование таблиц
\usepackage{ulem} % подчеркивания
\usepackage{geometry}
\usepackage{breqn}
\geometry{left=3cm}
\geometry{right=1.5cm}
\geometry{top=2.4cm}
\geometry{bottom=2.4cm}
\DeclareMathOperator*{\argmax}{\arg\!\max}

\begin{document}


\linespread{1.3} % полуторный интервал
\renewcommand{\rmdefault}{ftm} % Times New Roman
\frenchspacing
\thispagestyle{empty}


\begin{center}
\ \vspace{-3cm}

\includegraphics[width=0.5\textwidth]{msu.eps}\\

{\scshape Московский государственный университет имени М.~В.~Ломоносова}\\
Факультет вычислительной математики и кибернетики\\
Кафедра системного программирования

\vfill

{\LARGE Курсовая работа}

\vspace{1cm}

{\Huge\bfseries <<Определение языка сообщений социальной сети Twitter>>} \\

\end{center}

\vspace{1cm}

\begin{flushright}
  \large
  \textit{Выполнил студент 327 группы}\\
  М.~А.~Кольцов

  \vspace{5mm}

  \textit{Научный руководитель}\\
  В.~Д.~Майоров
\end{flushright}

\vfill

\begin{center}
Москва, 2014
\end{center}

\pagebreak
\tableofcontents
\pagebreak

\newtheorem{definition} {Определение}
\newtheorem{option} {Свойство}
\newtheorem{theorem} {Теорема}


\section{Введение}
	        В настоящее время человечество имеет доступ к огромному запасу знаний, накопленному за тысячи лет. Немалая часть этих знаний представляется
	        в виде текстов на различных языках. В связи с этим активно разрабатываются методы, предназначенные для автоматического извлечения
	        и преобразования информации, данной в символьном представлении. 
	        Возникло научное направление <<обработка естественных языков>>. Одной из его фундаментальных задач является определение языка текста. 


	        Стандартным подходом к этой задаче является применение машинного обучения. А именно, если у нас есть база из сотен документов 
	        на нескольких языках, то можно <<предсказать>> язык поступившего на рассмотрение документа, сравнив его с имеющимися. 
	        В общем случае, нужно по имеющимся данным построить так называемую модель, а затем все действия с текстами проводить в терминах 
	        этой модели. 
	        Классическим примером является метод, описанный в 1994 году: каждому документу сопоставим <<профиль документа>> --- упорядоченный по
	        числу встречаний список n-грамм --- последовательностей длины n подряд идущих символов. <<Профиль языка>> --- это совокупность профилей
	        документов, которые имеются на этом языке. Теперь, если нужно для какого-то документа определить язык, то последовательность
	        действий такова:
	        \begin{enumerate}
	        		\item Составляется профиль этого документа
	        		\item Сравнивается с имеющимися профилями языков
	        		\item Тот язык, чей профиль наиболее похож на профиль документа, объявляется результатом
	        \end{enumerate}
	          
	        Вышеописанный метод плохо работает для коротких сообщений. В то же время, поток информации в виде коротких шумных сообщений нельзя игнорировать ---
	        в социальной сети Twitter среднее количество сообщений в день составляет примерно 58 000 000, а длина каждого ограничена 140 символами. 
	        Такой формат текстов обусловил появление новых алгоритмов. В данной работе рассматриваются современные методы 
	        решения задачи определения языка, а также предлагается улучшение для одного из них. Проводится тестирование, показывающее
	        превосходство по полноте распознавания языка полученного результата над существующими.
  
	        
\section{Постановка задачи}
		\subsection{Формальное описание задачи автоматического определения языка}
		Пусть $L$ - множество меток, сопоставленных естественным языкам.
		По заданному тренировочному корпусу $$ T = \{(msg_{1}, lang_{1}), (msg_{2}, lang_{2}), \ldots, (msg_{N}, lang_{N}) \} $$
		(здесь $msg_{i}, i \in \overline{1..N},$ - текст на естественном языке, $lang_{i} \in L$ - метка этого языка) нужно построить классификатор,
		который произвольному входному сообщению $new\_msg$ на языке $some\_lang$ сопоставит метку $l \in L$, соответствующую этому языку,
		 или же сообщит, что язык текста невозможно достоверно распознать.
		\subsection{Цели и задачи курсовой работы}
		В данной работе в качестве текстов выступают так называемые <<твиты>> - сообщения из социальной сети Twitter\footnote{https://twitter.com/}, 
		а множество $L$ соответствует 18
		языкам, которые можно разделить на три группы по типу алфавита:
		\begin{itemize}
			\item Кириллические: болгарский, чувашский, русский, татарский, украинский
			\item Арабские: арабский, персидский (фарси), хинди, маратхи, непальский, урду
			\item Латинские: нидерландский, французский, английский, немецкий, итальянский, испанский, турецкий
		\end{itemize}
		Цели работы:
		\begin{enumerate}
			\item Исследовать современные решения задачи автоматического определения языка коротких сообщений
			\item Провести совместное сравнительное тестирование некоторых методов решения задачи и выяснить, действительно ли они показывают
			заявленное авторами качество классификации
			\item Исследовать зависимость качества классификации от различных факторов: степени нормализации сообщений, мощности обучающей 
			выборки, возможных предположений о структуре текстов
			\item Исследовать возможность улучшения какого-либо алгоритма решения задачи автоматического определения языка коротких сообщений	
		\end{enumerate}
		В рамках выполнения цели работы необходимо решить следующие задачи:
		\begin{enumerate}
			\item Собрать обучающий корпус, состоящий не менее чем из 800 твитов для каждого языка
			\item Реализовать один или несколько методов решения задачи автоматического определения языка коротких сообщений
			\item Организовать удобный интерфейс для автоматического тестирования методов
			\item Выбрать метрику качества классификации
		\end{enumerate}

\section{Обзор существующих решений}
		\subsection{Подход, основанный на частоте n-грамм}
		Для каждого языка составляется список из $K$ самых часто встречающихся n-грамм. Для $new\_msg$ составляется аналогичный список, для него
		определяется наиболее <<похожий>> из списков языков
		и на основании этого делается вывод о языке сообщения. 
		
		<<Похожесть>> двух упорядоченных списков характеризуется метрикой \textit{out-of-place}: 
		пусть в одном списке n-грамма $x$ стоит на позиции $i$, а в другом \nolinebreak --- $j$, тогда к расстоянию между списками добавляется $|i - j|$.
		
		
		Cavnar \& Trenkle показали, что при значении $K \approx 300$, составленные 
		профили языков очень хорошо эти языки характеризуют. Также они предлагают использовать длину n-грамм вплоть до 5.
		
		Этим подходом пользуются многие программные продукты, например, \textit{langid}, \textit{TextCat}, \textit{Google CLD}, о которых речь пойдёт
		в части 4.
		
		\noindent Плюсы и минусы:
		
		
		$+$ Малый размер модели
		
		$+$ Высокая скорость обучения и классификации
		
		$-$ Качество классификации сильно зависит от длины текста
		
		$-$ Много информации из документов не попадает в модель
		
		\subsection{Prediction by partial matching}
		Кодируются все имеющиеся документы, основываясь на частотах встречания цепочек из не более чем $n$ символов (чем больше частота --- тем короче
		код входящих в цепочку символов). Затем для $new\_msg$ вычисляется длина кода при помощи полученного кодирования и выбирается наиболее
		компактно кодирующий язык.
		
		Такой подход предлагается, например, в TODO
		
		\noindent Плюсы и минусы:
		
		$+$ 	Мало параметров
		
		$+$ Высокая точность классификации
		
		$-$ Для нормального функционирования нужны корпуса текстов, измеряемые мегабайтами
		
		\subsection{Подходы, использующие <<стандартные>> алгоритмы машинного обучения}
		Из документов вычленяются признаки, которые их характеризуют, и каждому документу сопоставляется вектор признаков. Далее применяется
		один из алгоритмов машинного обучения (например, логистическая регрессия или метод опорных векторов) для построения модели зависимости
		целевой переменной (языка сообщения) от вектора признаков. $New\_msg$ при классификации точно также заменяется на вектор признаков,
		а затем классификация проходит согласно выбранному алгоритму.
		
		Благодаря гибкости в выборе признаков, подход является перспективным по отношению к определению языка твитов. Так, например, в работах TODO
		используются, помимо текстовых, такие признаки: имя пользователя в Twitter; его местоположение; язык интерфейса; наиболее вероятный
		язык в предыдущих $k$ твитах этого пользователя; наиболее вероятный язык сущностей, на который ссылается пользователь в сообщении: текстов
		других пользователей, ссылок, тэгов.
		
		\noindent Плюсы и минусы:
		
		$+$ Хорошо разработанный набор стандартных алгоритмов
		
		$+$ Возможность настройки для выбранной предметной области
		
		$-$ Нужно тщательно подбирать признаки и алгоритм, дабы получить адекватный результат
		
		\subsection{Language identification graph-based approach (LIGA)}
		По каждому документу обучающей выборки строится граф $(V, E)$:
		 каждой вершине $v \in V$ графа соответствует пара $(trigram, count)$, где $trigram$ - это одна
		из триграмм, встретившихся в тексте, а $count$ - количество её вхождений. Будем обозначать за $v_{tr}$ соответствующую вершине $v$ триграмму
		($v_{tr} \neq u_{tr} \ \forall u \neq v$), за $v_{cnt}$ - количество её вхождений. 
		Ориентированное ребро $(u, v) \in E$ соответствует тому, что в тексте $u_{tr}$ следует непосредственно
		перед $v_{tr}$, а $(u, v)_{cnt}$ - количество раз, когда такое происходило.
		
		Далее, объединим полученные графы для всех документов одного языка $l \in L$: если у двух графов $(V', E')$ и $(V'', E'')$ есть вершины
		$v' \in V'$ и $v'' \in V''$ такие, что $v'_{tr} = v''_{tr}$, то в результирующем графе $(V_{l}, E_{l})$ должна быть вершина 
		$v \in V_{l}$ такая, что 
		$$v_{tr} = v'_{tr} = v''_{tr}$$ $$v_{cnt} = v'_{cnt} + v''_{cnt}$$
		Аналогично выполняется объединение рёбер.
		
		Последний шаг в построении модели: объединить графы $(V_{l}, E_{l})$, полученные $\forall l \in L$, в один. 
		Для этого каждой вершине $v \in V_{l}$
		(ребру $(u, v) \in E_{l}$) ставится дополнительно в соответствие метка языка $v_{lang}$ \ ($(u, v)_{lang}$). 
		Готовая модель представляет собой граф
		($\mathcal{V}, \mathcal{E}$), который получается следующим образом:
		$$ \mathcal{V} = \bigcup_{l \in L} V_{l}$$
		$$ \mathcal{E} = \bigcup_{l \in L} E_{l}$$
		
		Классификация происходит разбиением на триграммы, а затем <<укладыванием>> этих триграмм на пути графа. Формально, если
		$t_{1}, t_{2}, \ldots, t_{n}$ - триграммы сообщения $new\_msg$ в порядке их вхождения, то результатом будет
		$$ \argmax_{l} score_{l} ,$$
		где вектор \textit{score} длины $|L|$ определяется как:
		$$ score_{l} = \sum_{i=1}^{n} get\_v(t_{i}, l) + \sum_{i=1}^{N-1} get\_e(t_{i}, t_{i+1}, l)$$
		\[
 		get\_v(tr, l) =
 		  \begin{dcases}
  		   v_{cnt} \over \sum_{w \in \mathcal{V}} w_{cnt} & 
  		   \begin{split} 
					 \exists v \in \mathcal{V}: v_{tr}=tr \\ v_{lang}=l	
  		   	\end{split} \\
  		   0 & \quad otherwise
  		 \end{dcases}
		\]		
		
		\[
 		get\_e(tr_1, tr_2, l) =
 		  \begin{dcases}
  		   (u, v)_{cnt} \over \sum_{(w, q) \in \mathcal{E}} (w, q)_{cnt} & 
  		    \begin{split} 
					 \exists (u, v) \in \mathcal{E}:  u_{tr}=tr_1 \\ v_{tr}=tr_2 \\ (u, v)_{lang}=l
  		   	\end{split} \\
  		   0 & \quad otherwise
  		 \end{dcases}
		\]	
		
		Метод предложен в работе TODO. Такая модель позволяет зафиксировать одновременно частотность триграмм и их положение, при этом все триграммы
		из документов участвуют в классификации. Например, неправильное написание какого-то слова, будучи упущенным в n-граммном подходе (поскольку он
		учитывает лишь наиболее часто встречающиеся сочетания), добавит определённости при определении языка методом LIGA.		
		
		\noindent Плюсы и минусы:
		
		$+$ Высокая скорость обучения и классификации
		
		$+$ Максимально использует информацию из обучающей выборки
		
		$+$ Возможность дообучения <<на лету>>
		
		$+$ Возможность визуализации модели
		
		$-$ Большой объём модели и, как следствие, относительно высокие требования к памяти
			
\section{Подготовка к тестированию}
		\subsection{Сравниваемые системы}
			\subsubsection{TextCat}
			TextCat\footnote{http://odur.let.rug.nl/vannoord/TextCat/} --- авторская реализация подхода Canvar \& Trenkle TODO, основанного на n-граммах.
			Этот классический продукт часто берётся в качестве стандарта при сравнении алгоритмов определения языка. 
			Оригинальные модели языков достаточно устарели, но, к счастью, у программы есть возможность обучения.
			\subsubsection{Google CLD}
			Google compact language detector\footnote{https://code.google.com/p/cld2/} --- программный продукт, встроенный в браузер Chromium, 
			предназначенный для определения языка просматриваемой страницы. 
			Использует 4-граммы и умеет считывать метаинформацию
			о веб-страницах. Впрочем, для коротких текстов он тоже используется, например, в сервисе Google Translate. Система поставляется обученной
			на огромном корпусе текстов на более чем 100 языках.
			\subsubsection{Langid.py}
			Программа langid.py\footnote{https://github.com/saffsd/langid.py} за авторством Lui \& Baldwin, выпущенная в 2011 году, позиционируется
			как быстрое и точное решение задачи определения языка текста. Продукт поддерживает 97 языков.
			\subsubsection{LIGA}
			Реализация метода LIGA, выполненная мной в соответствии с работой TODO. Подход подробно описан в секции 3.4.
			\subsubsection{LogR}
			Реализация метода LogR из работы TODO. Общий подход описан в секции 3.3. Данная версия использует следующие признаки:
			\begin{itemize}
				\item Логарифм частоты встречания каждой уни-, би-, три- и квадграммы.
				\item Имя оставившего твит пользователя Twitter, его местоположение и отображаемое имя, а также их префиксы
				\item Индикатор: написано ли имя пользователя латиницей
				\item Встреченные в твите хэштеги
					\footnote{Хэштег - это последовательность символов без пробелов, начинающаяся с '$\#$', например: \textit{\#HarryPotter}, \textit{\#russia2014}}
				\item Встреченные в твите упоминания
					\footnote{Упоминание - это отображаемое имя пользователя, предварённое символом '@', например: \textit{@KremlinRussia}}
				\item Доменное имя 1 и 2 уровней, а также протокол для всех ссылок, встреченных в сообщении (при этом, если ссылка была сокращённой,
				например bit.ly/something, то происходит http-запрос для определения конечной цели)
			\end{itemize}
			\subsubsection{LIGAv2}
			Я предлагаю улучшенную версию алгоритма LIGA. Основное отличие заключается в изменении функций get\_v и get\_e:
			\[
 			get\_v\_v2(tr, l) =
 			  \begin{dcases}
  			   {(\log{|L| \over |\{r \in L | \exists v \in \mathcal{V}: v_{tr}=tr, v_{lang}=r\}|} + 1) \times  v_{cnt}} \over 
  			   \sum_{w \in \mathcal{V},\ w_{lang}=l} w_{cnt} & 
  			   \begin{split} 
						 \exists v \in \mathcal{V}: v_{tr}=tr \\ v_{lang}=l	
  			   	\end{split} \\
  			   0 & \quad otherwise
  			 \end{dcases}
			\]		
		
			\[
 			get\_e\_v2(tr_1, tr_2, l) =
 			  \begin{dcases}
  			   {(\log{|L| \over edges} + 1) \times (u, v)_{cnt}} 
  			   \over \sum_{(w, q) \in \mathcal{E},\ (w, q)_{lang}=l} (w, q)_{cnt} & 
  			    \begin{split} 
						 \exists (u, v) \in \mathcal{E}:  u_{tr}=tr_1 \\ v_{tr}=tr_2 \\ (u, v)_{lang}=l
  			   	\end{split} \\
  			   0 & \quad otherwise
  			 \end{dcases}
			\]	
			$$ edges = |\{r \in L \ | \ \exists (u, v) \in \mathcal{E}: u_{tr}=tr_1, v_{tr}=tr_2, (u, v)_{lang}=r\}| $$
			Мотивация к такому изменению следующая. Гораздо полезнее знать, насколько специфична данная триграмма данному языку, чем то, какой процент
			раз она встречалась в обучающей выборке вообще. Для этого в знаменателе общая сумма очков всех вершин графа (аналогично для рёбр) заменена 
			на сумму очков всех вершин подграфа $(V_{l}, E_{l})$. Также вводится логарифмический коэффициент, идея которого 
			навеяна idf\footnote{inverse document frequency}, и который характеризует <<уникальность>> данной триграммы в обучающей выборке.
			
			После таких изменений появляется шанс, что фраза \textit{"Привiт, груша"} будет корректно распознана как украинская, поскольку триграммы
			\textit{вiт} и \textit{ивi} будут иметь больший вес, чем остальные.
		\subsection{Обучающая выборка}       
       
\section{Примеры работы программы}
	\subsection{Пример 1}
		В данной системе матрицы $A$, $B$, $P$, $X_0$ являются единичными матрицам в $\mathbb{R}^3$, векторы $p$, $x_0$ --- нулевыми. Диапазон времени: $t_0 = 0$, $t_1 = 3$, фазовые ограничения отсутствуют. За статичные направления $l_1$ и $l_2$ взяты векторы $[1, 0, 0]$ и $[0, 1, 0]$, за динамичные --- $l_1(t) = [\sin(t); \cos(t); t], l_2(t) = [\cos(t); \sin(t); t]$.
	%\begin{center}
	%	\includegraphics[scale=0.75]{set_1.eps} \\
	%	Проекция множества достижимости на статическую плоскость $(l_1, l_2)$.
	%\end{center}		
	%\begin{center}
	%	\includegraphics[scale=0.75]{tube_1.eps} \\
	%	Проекция трубки достижимости на статическую плоскость $(l_1, l_2)$.
	\%end{center}			
	\subsection{Пример 2}
	В данной системе:
	$$A =
	\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 2 & 0 \\
		0 & 0 & 1,
	\end{pmatrix}, 
	B = 
	\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1,
	\end{pmatrix}
	P = 
	\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1,
	\end{pmatrix}
	$$	
	$$
		x_0 = [0, 0, 0]^{T}, p = [0, 0, 0]^{T}, t_0 = 0, t_1 = 3.
	$$
	В данной системе есть фазовые ограничения $x_1 \leqslant 3$.
	%\begin{center}
	%	\includegraphics[scale=0.75]{set_2.eps} \\
	%	Проекция множества достижимости на статическую плоскость $(l_1, l_2)$.
	%\end{center}		
	%\begin{center}
	%	\includegraphics[scale=0.75]{tube_2_1.eps} \\
	%	Проекция трубки достижимости на статическую плоскость $(l_1, l_2)$.
	%\end{center}	
	%\begin{center}
	%	\includegraphics[scale=0.75]{tube_2_2.eps} \\
	%	Проекция трубки достижимости на статическую плоскость $(l_1, l_2)$.
	%\end{center}	
		
	\subsection{Пример 3}
		Рассмотрим колебательную систему из задания прошлого семестра. В этой системе:
	$$A =
	\begin{pmatrix}
		0 & 0 & 1 & 0 \\
		0 & 0 & 0 & 1 \\
		-2 \frac{g}{l_1} & \frac{g}{l_1} & 0 & 0 \\
		2 \frac{g}{l_2} & -2\frac{g}{l_2} & 0 & 0,
	\end{pmatrix}, 
	B = 
	\begin{pmatrix}
		0 \\
		0 \\
		0 \\ 
		1, 
	\end{pmatrix}
	P = 
	\begin{pmatrix}
		1 & 0 & 0 & 0 \\
		0 & 1 & 0 & 0\\
		0 & 0 & 1 & 0 \\
		0 & 0 & 0 & 1,
	\end{pmatrix}
	$$	
	$$
		x_0 = [0.1, 0.3, 1, 1]^{T}, p = [0, 0, 0, 0]^{T}, t_0 = 0, t_1 = 3, l_1 = 2, l_2 = 1.
	$$		
	На систему наложены фазовые ограничения $|x_1| \leqslant y_1$,  $y_1 = 1$.
	
	\begin{center}
%		\includegraphics[scale=0.75]{set_3.eps} \\
		\begin{tikzpicture}
		\begin{axis}[xlabel=errors, ylabel=percentage]
		\addplot[blue!80!black] coordinates
			{(-23, 1.5) (0, 1.7) (10, 1.96)};
		\addlegendentry{liga}
		\end{axis}
		\end{tikzpicture}
		Проекция множества достижимости на статическую плоскость $(l_1, l_2)$.
	\end{center}		
	\begin{center}
%		\includegraphics[scale=0.75]{tube_3_1.eps} \\
		Проекция трубки достижимости на статическую плоскость $(l_1, l_2)$.
	\end{center}	
	\begin{center}
%		\includegraphics[scale=0.75]{tube_3_2.eps} \\
		Проекция трубки достижимости на статическую плоскость $(l_1, l_2)$.
	\end{center}	
	
	Из рисунков трубки достижимости видно, что фазовые ограничения выполняются.
\section{Библиография}
  \begin{thebibliography}{99}
    \bibitem{newllang} \emph{Голубев~Ю.~Ф.} Основы теоретической механики: Учебник. 2-е изд., перераб. и дополн. --- М.:Изд-во МГУ, 2000.
    \bibitem{Modeling} \emph{P. Gagarinov, Alex A. Kurzhanskiy} Ellipsoial toolbox: ver. 2.0 beta 1, 2013.
  \end{thebibliography}
\end{document}
